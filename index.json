[
  {
    "id": "ai-business-trends-2025",
    "title": "AI Business Trends 2025",
    "description": "A comprehensive analysis of emerging AI business trends and their market impact for 2025",
    "tags": [
      "AI",
      "business",
      "trends",
      "market analysis",
      "technology"
    ],
    "created": "2025-04-22T13:45:00.000Z",
    "updated": "2025-04-23T09:15:00.000Z",
    "path": "ai-business-trend-2025.md",
    "url": "/view/ai-business-trends-2025",
    "content": "---\ntitle: AI Business Trends 2025\ndescription: A comprehensive analysis of emerging AI business trends and their market impact for 2025\ntags: [AI, business, trends, market analysis, technology]\ncreated: 2025-04-22T13:45:00Z\nupdated: 2025-04-23T09:15:00Z\nmarkmap:\n  colorFreezeLevel: 2\n  maxWidth: 300\n---\n# AI Business Trends 2025\n## About the Report\n### Provides insights for AI strategy to 2025 and beyond\n### Based on data insights from multiple sources\n- The ROI of Gen AI\n- Research by Google Cloud and National Research Group\n- Google Trends\n- Third-party research\n- Google AI thought leaders' insights\n- TIME Magazine's Best Inventions of 2024\n### Used NotebookLM to identify top 5 trends\n## Introduction\n### AI has shifted global market dynamics\n- Catalyzed rapid innovation\n- Radical transformation in how organizations operate, compete, and innovate\n## Key Impacts of AI\n### AI early adopters dominate the market\n- Capitalized companies lead in customer experience\n- Gain market share over traditional competitors\n### Capital investment in AI has taken off\n- AI maturity is a key indicator of economic health\n- Governments rethink policies and regulations\n- Leadership strategies extend beyond humans\n### Demand for data center capacity surges\n- AI adoption in enterprise infrastructure is expected to increase by over 30% by 2026\n- Data center capacity demand is expected to rise by 33% per year through 2030\n### Hyperscalers help organizations remove barriers to enterprise AI adoption\n- Investing in new data centers with AI-optimized infrastructure\n- Includes Google's custom-designed TPUs, NVIDIA GPUs, networking, and storage\n### AI agents go mainstream\n- Drive improvements across the value chain\n- Used to pursue goals and complete tasks\n- Race to deliver sophisticated features\n### Businesses have embraced multimodal LLMs to automate core operations\n- Shift from experimentation to scaling AI\n- Focus on measurable outcomes\n- $250 billion business process outsourcing (BPO) market is ripe for AI automation\n- Organizations establish risk management, cost control, and governance\n## Top 5 Trends\n### **Multimodal AI**: Unleash the power of context\n- 2025 is a pivotal year for enterprise AI adoption\n- Driven by multimodal learning and contextual awareness\n- Global multimodal AI market size in 2025: $2.4B\n- Global multimodal AI market size by end of 2037: $98.9B\n- Mirrors human learning by integrating diverse data sources\n  - Images, video, and audio in addition to text\n- Improves complex data analysis, streamlines workflows\n- Bayer: AI with medical imaging to transform data\n- Prudential: Google's MedLM to simplify medical documents\n### **AI agents**: The evolution from chatbots to multi-agent systems\n- AI applications evolved from chatbots into sophisticated AI agents\n- Multi-agent systems are the next phase of evolution\n- AI agents show reasoning, planning, and memory\n- Can seamlessly manage complex workflows and automate business processes\n- Workers with less experience and skills improved output with AI agents\n- Multi-agent systems coordinate individual agents\n- Six AI agents that drive value\n  - Employee agents\n  - Code agents\n### **Assistive search**: The next frontier for knowledge work\n- AI has changed how the world discovers information\n- Shift from retrieving to creating knowledge\n- Predicted size of enterprise search market by 2031: $12.9B\n- Benefits of AI-powered enterprise search\n  - Faster access to data\n  - More advanced and intuitive searches\n  - Deeper, AI-powered insights\n- Brands deliver new levels of service with AI-powered search tools\n  - Can receive helpful assistance and contextualized insights\n### **AI-powered customer experience**: So seamless, it's almost invisible\n- Customer engagement applications and enterprise search combine to make customer experience seamless\n- Customer service and support is the top priority area for new gen AI initiatives\n- AI solves common CX challenges\n  - Customer support\n  - Customer sentiment\n  - Personalization\n- AI-powered CX is on the rise across industries\n  - Alaska Airlines\n  - NotCo\n  - Discover Financial\n  - Klook\n  - KDDI Corporation\n### **Security gets tighter—and tougher—with AI**\n- In 2025, AI will be widely adopted into security and privacy\n- AI is used in novel ways to bolster security\n  - Rule creation\n  - Attack simulation\n  - Compliance violation detection\n- Average reduction in breach costs when organizations apply security AI and automation: $2.2M\n- Companies tighten security using AI tools\n  - Bayer\n  - Apex Fintech\n  - One New Zealand\n## Conclusion\n### Multimodal AI is making interactions more intuitive\n### AI agents are streamlining workflows\n### AI-powered search is revolutionizing knowledge discovery\n### AI-driven customer experiences are more personalized\n### AI security solutions are fortifying defenses\n### Businesses can solve problems in bold ways with AI"
  },
  {
    "id": "model-context-protocol-mcp",
    "title": "Model Context Protocol (MCP)",
    "description": "Comprehensive explanation of MCP framework for enabling LLMs to access external data sources.",
    "tags": [
      "mcp",
      "anthropic",
      "claude",
      "llm",
      "data-access",
      "api",
      "tools",
      "workflow",
      "implementation"
    ],
    "created": "2025-04-23T20:46:54.055Z",
    "updated": "2025-04-23T20:46:54.056Z",
    "path": "explain.md",
    "url": "/view/model-context-protocol-mcp",
    "content": "---\ntitle: Model Context Protocol (MCP)\ntags: [mcp, anthropic, claude, llm, data-access, api, tools, workflow, implementation]\ndescription: Comprehensive explanation of MCP framework for enabling LLMs to access external data sources.\nmarkmap:\n  colorFreezeLevel: 2\n  maxWidth: 300\n---\n# Model Context Protocol (MCP)\n## Problem Addressed\n* LLMs lacking direct access to external data\n  * Example: Claude's inability to summarize GitHub commits initially\n* Need to give LLMs access to various data sources\n  * Private databases\n  * Google Docs\n  * File systems\n  * Slack messages\n## MCP Overview\n* Initiative by Anthropic (creators of Claude)\n* Aims to provide LLMs with access to your data\n## Key Entities in MCP\n### Client/Host\n* Application initiating the query\n* Examples: Claude Desktop, server application\n* Often used interchangeably\n* Host can contain multiple clients\n### LLM\n* The language model processing the request\n* Example: Claude\n### Data Source\n* Location of the desired data\n* Examples: GitHub repositories, databases, file systems\n### MCP Server\n* Enables LLM access to data sources\n* Tiny program running locally or on-premises\n* Can access data source APIs (e.g., GitHub REST API)\n* **/tools Endpoint**\n  * Returns a list of available tools the server can perform\n  * Initially plain text\n  * Implemented as JSON with name, description, and schema\n  * Examples: `list commits`, `create update file`, `create pull request`\n* Implements the logic for each tool\n  * Calls relevant APIs\n  * Processes and returns data\n## MCP Workflow\n### Step 1\n* Client asks the preconfigured MCP server for available tools\n### Step 2\n* Client sends the user query and tool information to the LLM\n### Step 3\n* LLM responds by requesting the use of a specific tool\n### Step 4\n* Client instructs the MCP server to execute the requested tool with necessary parameters\n### Step 5\n* MCP server interacts with the data source (e.g., GitHub API)\n* Retrieves the requested data\n* Returns data to the client\n### Step 6\n* Client sends the original query along with the retrieved data to the LLM\n### Step 7\n* LLM processes the data and generates a response to the user\n### Background\n* Multiple queries are executed in the background\n## Implementation Details\n### Reference MCP Servers\n* Available on the [model-context-protocol](https://github.com/model-context-protocol) GitHub organization\n* Pre-implemented for various services\n  * File System\n  * Google Drive\n  * GitHub\n  * Google Maps\n  * PostgreSQL\n### Client Configuration (e.g., Claude Desktop)\n* Requires modifying a configuration file (`config.json`)\n* Specifies the details of the MCP server to use\n* Instructions provided with reference servers\n### Running the MCP Server\n* Can be run using Docker\n* May also support NPM/NPX or Python commands\n* Requires necessary API keys/tokens (e.g., GitHub personal access token)\n### Verification\n* Claude Desktop displays a hammer icon with the number of available MCP tools after successful configuration\n## Beyond Tools\n* MCP servers can potentially support more than just tools\n  * Sampling Roots\n  * Template Prompts\n## Future Development\n* Implementation of custom MCP clients"
  },
  {
    "id": "google-s-agent-to-agent-a2a-protocol",
    "title": "Google's Agent-to-Agent (A2A) Protocol",
    "description": "An overview of Google's A2A protocol for enabling communication between AI agents",
    "tags": [
      "AI",
      "agents",
      "protocol",
      "Google",
      "communication",
      "A2A"
    ],
    "created": "2025-04-20T11:30:00.000Z",
    "updated": "2025-04-22T15:45:00.000Z",
    "path": "google-a2a.md",
    "url": "/view/google-s-agent-to-agent-a2a-protocol",
    "content": "---\ntitle: Google's Agent-to-Agent (A2A) Protocol\ndescription: An overview of Google's A2A protocol for enabling communication between AI agents\ntags: [AI, agents, protocol, Google, communication, A2A]\ncreated: 2025-04-20T11:30:00Z\nupdated: 2025-04-22T15:45:00Z\nmarkmap:\n  colorFreezeLevel: 2\n  maxWidth: 300\n---\n# Google's Agent-to-Agent (A2A) Protocol\n## Introduction to A2A\n* **Standard for AI agent communication**\n* Similar to **Agent-to-Tool (MCP)**\n* A2A is revolutionary\n* Initial launch not highly publicized\n* Following a similar adoption path as MCP\n* Takes time for technical protocols to be understood\n* Will be a **big deal**\n* Importance for the future of AI agents\n## Key Features and Concepts of A2A\n* Google announcement with many partners\n    * Salesforce\n    * Accenture\n    * MongoDB\n    * Neoforj\n    * Oracle\n    * Langchain\n    * Others\n* **Agent Card**: Describes agent capabilities, interaction, authentication\n* **Server and Client Architecture**: Similar to microservices\n    * Agents as **API endpoints (servers)**\n    * Clients (agents or users) consume A2A services\n* **Tasks**: Requests with identifiers and payloads\n* Support for **push notifications**\n* **Agent Discovery**: Real-time learning of other agent capabilities\n* **Open-source** on GitHub\n* High-level architecture, not a downloadable tool\n## Benefits of A2A\n* More accessible and **standardized agent communication**\n* Flexibility in building agents (different frameworks, hosting)\n* **Dynamic integration** of agents\n* Reduces risk of breaking integrations during updates\n* Enables agent discovery\n* Potential for complete AI backend with MCP\n## Relationship with MCP\n* **Complimentary**: Operate on different layers\n    * A2A: Agent to Agent\n    * MCP: Agent to Tool\n* Example: Client agent (A2A) calls server agent using Brave (MCP) for web search\n* Together with a frontend (like Lovable), can build end-to-end AI applications\n## Practical Implementation (Example)\n* Basic Python server and client implementation\n* Server:\n    * Integration with MCP server (Brave via Pydantic AI)\n    * Agent card definition (name, description, capabilities, etc.)\n    * Endpoint to fetch agent card (`/agent.json`)\n    * Endpoint to handle tasks\n* Client:\n    * Fetches agent card\n    * Generates task ID\n    * Builds JSON payload for the request\n    * Sends task request to server endpoint\n    * Handles response\n## Concerns and Challenges with A2A\n* **Testing complexity** (distributed nodes, LLM unpredictability)\n* **Security concerns** (increased attack surface, third-party data)\n* Authentication challenges across the system\n* **Hidden complexity** (black box nature)\n* Difficulty in **error attribution** in distributed systems\n* Accountability can be difficult\n## Future Outlook\n* Protocol has significant potential\n* Foundation laid out by Google needs further development\n* Expectation of solutions to current challenges\n* Potential for easy building of scalable and secure AI systems\n* Wide adoption expected over time (potentially 1-2 years)"
  },
  {
    "id": "mcp-key-entities-and-concepts",
    "title": "MCP Key Entities and Concepts",
    "description": "Comprehensive overview of key components and concepts in the Model Context Protocol ecosystem.",
    "tags": [
      "mcp",
      "llm",
      "client",
      "data-source",
      "server",
      "tools",
      "protocol",
      "architecture"
    ],
    "created": "2025-04-23T20:46:54.057Z",
    "updated": "2025-04-23T20:46:54.057Z",
    "path": "key-entities.md",
    "url": "/view/mcp-key-entities-and-concepts",
    "content": "---\ntitle: MCP Key Entities and Concepts\ntags: [mcp, llm, client, data-source, server, tools, protocol, architecture]\ndescription: Comprehensive overview of key components and concepts in the Model Context Protocol ecosystem.\nmarkmap:\n  colorFreezeLevel: 2\n  maxWidth: 300\n---\n# Model Context Protocol (MCP)\n## Key Entities\n### **Client/Host**\n* Application that initiates the query\n* Acts as an intermediary between the user and the LLM\n* Examples: **Claude Desktop**, custom server application\n* Can contain multiple clients (host definition)\n* Configures and interacts with the MCP Server\n* Sends the initial query and tool information to the LLM\n* Executes the tool by calling the MCP Server\n* Sends the final query with retrieved data to the LLM\n### **LLM**\n* The **language model** that processes the user's request\n* Example: **Claude**\n* Initially lacks direct access to external data sources\n* Receives the user query and available tools from the Client\n* Determines the need for a specific tool\n* Instructs the Client to use the tool\n* Processes the data provided by the Client (retrieved via MCP Server)\n* Generates the final response to the user\n### **Data Source**\n* The location where the desired data resides\n* Examples: **GitHub repositories**, private databases, Google Docs, file systems, Slack messages\n* Accessed indirectly by the LLM through the MCP Server\n* Provides the raw data requested by the MCP Server\n### **MCP Server**\n* A **program** that acts as a bridge between the LLM and data sources\n* Runs locally or on-premises\n* Discovers and exposes its capabilities through the **/tools endpoint**\n* Implements the logic for each advertised tool\n* Can access data source APIs (e.g., GitHub REST API)\n* Receives requests from the Client to execute specific tools\n* Interacts with the Data Source to retrieve data\n* Returns the retrieved data to the Client\n## Key Concepts\n### **Problem of Limited LLM Data Access**\n* LLMs like Claude initially cannot directly access external data\n* Prevents them from fulfilling requests requiring external information (e.g., summarizing GitHub commits)\n### **MCP as an Enabling Protocol**\n* An initiative to give LLMs access to external data\n* Achieves this access **without giving the LLM direct access** to the data source\n### **Tools**\n* Specific actions or functionalities that the MCP Server can perform\n* Advertised through the **/tools endpoint**\n* Examples: `list commits`, `create update file`, `create pull request`\n* Have a name, description, and schema defining required parameters\n* The LLM instructs the Client to use these tools\n### **/tools Endpoint**\n* An endpoint on the MCP Server that lists the available tools\n* Initially returns plain text, but implemented as a JSON object\n* JSON includes the tool's name, description, and input schema\n### **MCP Workflow (Conceptual)**\n* Client discovers available tools from the MCP Server\n* Client sends the user query and tool info to the LLM\n* LLM requests the use of a specific tool\n* Client tells the MCP Server to execute the tool\n* MCP Server retrieves data from the Data Source\n* Client sends the query and retrieved data to the LLM\n* LLM generates a response based on the provided data\n### **Abstraction of Data Access**\n* Claude (the LLM) **never directly interacts** with GitHub or other data sources\n* All data access is mediated by the MCP Server\n* The LLM only knows that a \"tool\" exists and can be used to get information"
  },
  {
    "id": "large-language-models-and-efficient-adaptation",
    "title": "Large Language Models and Efficient Adaptation",
    "description": "A comprehensive guide to Large Language Models (LLMs) and techniques for their efficient fine-tuning and adaptation",
    "tags": [
      "LLM",
      "AI",
      "machine learning",
      "PEFT",
      "fine-tuning",
      "NLP",
      "transformers"
    ],
    "created": "2025-04-18T09:20:00.000Z",
    "updated": "2025-04-21T14:30:00.000Z",
    "path": "llm-concepts.md",
    "url": "/view/large-language-models-and-efficient-adaptation",
    "content": "---\ntitle: Large Language Models and Efficient Adaptation\ndescription: A comprehensive guide to Large Language Models (LLMs) and techniques for their efficient fine-tuning and adaptation\ntags: [LLM, AI, machine learning, PEFT, fine-tuning, NLP, transformers]\ncreated: 2025-04-18T09:20:00Z\nupdated: 2025-04-21T14:30:00Z\nmarkmap:\n  colorFreezeLevel: 2\n  maxWidth: 300\n---\n# Large Language Models (LLMs) and Efficient Adaptation\n## Large Language Models (LLMs) Basics\n* Definition: Deep learning algorithm for various NLP tasks\n* Use transformer models, trained on massive datasets\n* Recognize, translate, predict, or generate text/content\n* Also known as neural networks (NNs)\n* Can be trained for tasks beyond human language\n* Require pre-training and fine-tuning\n* Have large numbers of parameters (knowledge bank)\n* Transformer Model: Common LLM architecture\n  - Encoder and decoder\n  - Tokenizes input, finds relationships between tokens\n  - Uses self-attention mechanisms for faster learning\n  - Considers context to generate predictions\n* Key Components\n  - Embedding layer: Captures semantic and syntactic meaning\n  - Feedforward layer (FFN): Gleans higher-level abstractions\n  - Recurrent layer: Interprets words in sequence\n  - Attention mechanism: Focuses on relevant parts of input\n* Types of LLMs\n  - Generic/Raw: Predict next word\n  - Instruction-tuned: Predict responses to instructions (sentiment analysis, text/code generation)\n  - Dialog-tuned: Trained for conversation (chatbots)\n* Relation to Generative AI\n  - LLMs are a type of generative AI\n  - Generative AI generates various content (text, code, images, etc.)\n* How LLMs Work\n  - Input -> Encoding -> Decoding -> Output Prediction\n  - Training (Pre-training): Unsupervised learning on large textual datasets\n  - Learns meaning of words and relationships\n  - Distinguishes words based on context\n  - Fine-tuning: Adapts model for specific tasks (e.g., translation)\n  - Prompt-tuning: Uses few-shot or zero-shot prompting for specific tasks\n* Use Cases\n  - Information retrieval (search engines)\n  - Sentiment analysis\n  - Text generation\n  - Code generation\n  - Chatbots and conversational AI\n  - Sentence completion, question answering, text summarization\n* Benefits\n  - Broad range of applications\n  - Continually improving with more data/parameters (in-context learning)\n  - Learn fast (in-context learning requires few examples)\n* Limitations and Challenges\n  - Hallucinations: Producing false or unintended outputs\n  - Security risks: Data leaks, phishing, misinformation\n  - Bias in training data leads to biased outputs\n  - Consent issues with training data (copyright, privacy)\n  - Scaling and maintenance can be difficult\n  - Deployment requires expertise\n* Examples of Popular LLMs\n  - PaLM, BERT, XLNet, GPT (including fine-tuned versions)\n\n## Efficient Utilization and Customization\n* **Sampling**: Generating text by probabilistically selecting tokens\n  - Introduces randomness for diverse outputs\n  - Techniques: Temperature scaling, top-k/top-p sampling\n  - Example: \"The cat jumped over the fence\" vs. \"The cat climbed the tree\"\n  - Use for creative tasks, conversational responses\n* **Tokenizer**: Converts raw text to numerical tokens\n  - Breaks text into subwords, words, or characters (BPE, WordPiece, SentencePiece)\n  - Maps tokens to numerical IDs\n  - Adds special tokens ([CLS], [SEP])\n  - Used during training and inference\n* **Sharding**: Dividing large models for efficient storage and computation across devices\n  - Splits model parameters across GPUs/nodes\n  - Reduces memory overhead\n  - Enables training/inference on very large models\n  - Essential for deploying large-scale models\n* **Checkpoints**: Saving model state during training\n  - Includes weights, optimizer states, metadata\n  - Allows resuming interrupted training\n  - Enables evaluation of intermediate performance\n  - Critical for long-running training\n\n## Fine-Tuning\n* Adapts a pre-trained LLM to specific tasks using task-specific data\n* Updates model's parameters\n* Can be full fine-tuning (all parameters) or parameter-efficient\n* Example: Fine-tuning on medical texts for healthcare Q&A\n* Used for specialization in domains/tasks\n\n## Parameter-Efficient Fine-Tuning (PEFT)\n* Updates only a subset of parameters, keeping most frozen\n* Reduces computational costs and improves efficiency\n* Ideal for efficient adaptation of large models\n* **How it Works**\n  - Selectively tunes a smaller number of parameters\n  - Reduces computational load while maintaining performance\n  - Achieves high-performing models with fewer resources\n* **Common Approaches**\n  - Adaptive Budget Allocation: Dynamically allocates resources to important layers\n  - Low-Rank Adaptation (LoRA): Adds trainable low-rank matrices to specific layers\n  - Freezes most original weights\n  - Captures task-specific adjustments\n  - Prefix Tuning: Adds small trainable parameters to the input sequence (prefixes)\n  - Gradient-Based PEFT: Optimizes most influential parameters based on gradient information\n* **Difference from Traditional Fine-Tuning**\n  - Fine-tuning retrains all parameters, resource-intensive\n  - PEFT focuses on a smaller subset, more scalable\n* **Benefits**\n  - Cost-Efficiency: Lower computational costs\n  - Faster Training: Quicker training times\n  - Adaptability: Applicable across various domains (NLP, computer vision)\n  - Resource Optimization: Effective use of limited hardware\n  - High Performance: Comparable results to full fine-tuning\n* **Step-by-Step Guide**\n  - Select Base Model\n  - Identify Critical Parameters\n  - Apply Adaptive Budget Allocation\n  - Train the Model\n  - Evaluate the Model\n  - Deploy and Monitor\n* **Real-World Applications**\n  - Healthcare: Medical imaging diagnosis\n  - Finance: Fraud detection\n  - Natural Language Processing: Chatbots, virtual assistants (language adaptation)\n  - Autonomous Vehicles: Real-time decision-making with fewer resources\n* **LoRA for Fine-Tuning**: Parameter-efficient method updating low-rank matrices\n* **Tools for PEFT**: Hugging Face PEFT library, PyTorch, TensorFlow"
  },
  {
    "id": "why-use-neuronwiz",
    "title": "Why Use NeuronWiz",
    "description": "Explore the key benefits and features of the NeuronWiz mind mapping platform",
    "tags": [
      "demo",
      "features",
      "overview",
      "getting-started"
    ],
    "created": "2025-04-23T10:00:00.000Z",
    "updated": "2025-04-23T10:00:00.000Z",
    "path": "why-use-neuronwiz.md",
    "url": "/view/why-use-neuronwiz",
    "content": "---\ntitle: Why Use NeuronWiz\ndescription: Explore the key benefits and features of the NeuronWiz mind mapping platform\ntags: [demo, features, overview, getting-started]\ncreated: 2025-04-23T10:00:00Z\nupdated: 2025-04-23T10:00:00Z\n---\n\n# Why Use NeuronWiz\n\n## Visualize Complex Knowledge\n\n### Transform Linear Notes\n- Convert traditional notes into interactive knowledge networks\n- Break free from sequential organization\n- See relationships between concepts clearly\n\n### Improve Understanding\n- Leverage visual spatial memory\n- Identify connections between related topics\n- Grasp complex systems more intuitively\n\n### Enhance Learning Retention\n- Boost recall with visual associations\n- Reinforce concepts through hierarchical organization\n- Create mental anchors with visual structure\n\n## Share Your Thinking\n\n### Export Options\n- High-quality SVG vector format\n- Print-ready PNG images\n- Preserve all structure and formatting\n\n### Presentation Ready\n- Include in slides and documents\n- Present ideas in meetings\n- Share with colleagues via email\n\n### Collaboration Features\n- Share links directly to specific mind maps\n- Embed in websites and documentation\n- Use in educational settings\n\n## Find Information Fast\n\n### Powerful Search\n- Full-text search across all mind maps\n- Find related concepts quickly\n- Locate specific information in large knowledge bases\n\n### Quick Navigation\n- Jump between connected topics\n- Expand and collapse sections as needed\n- Focus on relevant information\n\n### Smart Indexing\n- Content automatically indexed\n- Search results ranked by relevance\n- Tags enhance discoverability\n\n## Organize with Tags\n\n### Flexible Categorization\n- Create custom tagging systems\n- Assign multiple tags to each mind map\n- Filter content by tag combinations\n\n### Knowledge Organization\n- Group related concepts together\n- Create project-specific collections\n- Build a personal knowledge taxonomy\n\n### Discovery Through Tags\n- Find related content via shared tags\n- Explore your knowledge base by category\n- Identify knowledge gaps and connections\n\n## Access Anywhere\n\n### Responsive Design\n- Optimized for desktop monitors\n- Works seamlessly on tablets\n- Accessible on mobile phones\n\n### Cross-Platform Compatibility\n- No installation required\n- Works on all modern browsers\n- Consistent experience across devices\n\n### Cloud Accessibility\n- Access your mind maps from anywhere\n- No need to sync files manually\n- Always up-to-date content\n\n## Work Your Way\n\n### Light & Dark Themes\n- Light mode for daytime use\n- Dark mode for reduced eye strain\n- Automatic theme switching with system preferences\n\n### Customization Options\n- Adjust zoom levels to your preference\n- Configure expanded/collapsed node state\n- Customize display settings\n\n### Keyboard Navigation\n- Efficient shortcuts for power users\n- Navigate without using the mouse\n- Quick commands for common actions"
  },
  {
    "id": "mcp-workflow",
    "title": "MCP Workflow",
    "description": "Step-by-step process of how MCP enables LLMs to access external data sources.",
    "tags": [
      "mcp",
      "workflow",
      "tools",
      "llm",
      "client",
      "steps"
    ],
    "created": "2025-04-23T20:46:54.058Z",
    "updated": "2025-04-23T20:46:54.058Z",
    "path": "workflow.md",
    "url": "/view/mcp-workflow",
    "content": "---\ntitle: MCP Workflow\ntags: [mcp, workflow, tools, llm, client, steps]\ndescription: Step-by-step process of how MCP enables LLMs to access external data sources.\nmarkmap:\n  colorFreezeLevel: 2\n  maxWidth: 300\n---\n# MCP Workflow\n## Step 1: Tool Discovery\n* **Client (e.g., Claude Desktop) queries the MCP Server**\n* Asks for available tools\n* MCP Server responds with a list of its capabilities\n  * Example: `list commits`, `create update file`\n## Step 2: Initial User Query to LLM\n* Client sends the **user's query**\n* Includes the **available tools** information received from the MCP Server\n* Sent to the **LLM (e.g., Claude)**\n## Step 3: LLM Requests Tool Usage\n* **LLM acknowledges lack of direct data access**\n* Identifies a relevant tool from the provided list\n* **Instructs the Client to use the specific tool**\n* Asks the Client to call the tool and then query the LLM again\n## Step 4: Client Executes the Tool\n* **Client communicates with the MCP Server**\n* Tells the server to execute the requested tool\n* Provides necessary parameters based on the user's query\n  * Example: Repository owner, repository name for `list commits`\n## Step 5: MCP Server Interacts with Data Source\n* **MCP Server accesses the relevant API**\n  * Example: GitHub REST API\n* Retrieves the requested data\n  * Example: List of recent commits\n* Returns the data to the Client\n## Step 6: Client Submits Data and Query to LLM\n* **Client sends the original user query to the LLM again**\n* **Includes the data retrieved by the MCP Server**\n  * Example: The list of recent commits from GitHub\n* Provides the LLM with the necessary context\n## Step 7: LLM Generates Response\n* **LLM processes the provided data**\n* Applies natural language processing\n* Generates a summarized or relevant response to the user\n* Response is based on the data obtained through the MCP Server\n## Background Processes\n* **Multiple queries happen in the background**\n* Initial query + tool discovery + LLM tool request + tool execution + final query with data"
  }
]